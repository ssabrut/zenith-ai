{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeleco/Documents/Github/zenith-ai/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "def extract_pdf_data(file_path):\n",
    "    print(f\"ðŸš€ Processing: {file_path} (This uses OCR and may take time...)\")\n",
    "    \n",
    "    # --- CORE EXTRACTION ---\n",
    "    elements = partition_pdf(\n",
    "        filename=file_path,\n",
    "        strategy=\"hi_res\",\n",
    "        infer_table_structure=True,\n",
    "        extract_images_in_pdf=True,\n",
    "        extract_image_block_types=[\"Image\", \"Table\"],\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=4000,\n",
    "        new_after_n_chars=3200,\n",
    "        combine_text_under_n_chars=800,\n",
    "        languages=[\"eng\", \"ind\"]\n",
    "    )\n",
    "    \n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9b1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove Page Markers (e.g., \"--- PAGE 100 ---\")\n",
    "    text = re.sub(r'---\\s*PAGE\\s*\\d+\\s*---', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove Image Placeholders (e.g., \"[Image 184]\")\n",
    "    text = re.sub(r'\\[Image\\s*\\d+\\]', '', text)\n",
    "    \n",
    "    # Fix OCR Currency Glitches (The \"RpRp\" problem)\n",
    "    text = re.sub(r'(Rp\\.?\\s*){2,}', 'Rp ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Rp\\.(\\d)', r'Rp \\1', text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove excessive whitespace / headers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Filter out navigational noise\n",
    "    noise_phrases = [\"Table of CONTENTS\", \"Back to top\", \"ERHA ULTIMATE PRICE LIST\"]\n",
    "    for phrase in noise_phrases:\n",
    "        text = text.replace(phrase, \"\")\n",
    "        \n",
    "    return text.strip()\n",
    "\n",
    "def enrich_price_data(text):\n",
    "    price_pattern = r'Rp\\s*[\\d\\.]+(?:,\\d{2})?'\n",
    "    matches = re.findall(price_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        return f\"[PRICELIST ITEM] {text}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2dcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "qdrant_host = \"http://localhost:6333\"\n",
    "collection_name = os.getenv(\"QDRANT_COLLECTION\")\n",
    "qdrant_client = QdrantClient(url=qdrant_host)\n",
    "collections = qdrant_client.get_collections()\n",
    "existing_collections = [collection.name for collection in collections.collections]\n",
    "\n",
    "if collection_name not in existing_collections:\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=768, distance=Distance.COSINE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9211a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Processing: ../data/pdf/724126666-ERHA-Ultimate-Pricelist-24.pdf (This uses OCR and may take time...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   found 96 chunks. Embedding...\n",
      "   âœ… Uploaded 96 vectors.\n",
      "ðŸš€ Processing: ../data/pdf/661627558-Katalog-Dermies-Max-by-Erha-Hiress.pdf (This uses OCR and may take time...)\n",
      "   found 21 chunks. Embedding...\n",
      "   âœ… Uploaded 21 vectors.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "ollama_embedding = OllamaEmbeddings(\n",
    "    model=os.getenv(\"OLLAMA_EMBEDDING_MODEL\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "for fname in os.listdir(\"../data/pdf\"):\n",
    "    fpath = os.path.join(\"../data/pdf\", fname)\n",
    "    \n",
    "    elements = extract_pdf_data(fpath)\n",
    "\n",
    "    points = []\n",
    "    print(f\"   found {len(elements)} chunks. Embedding...\")\n",
    "\n",
    "    for i, el in enumerate(elements):\n",
    "        text_content = el.text\n",
    "\n",
    "        cleaned_text = clean_text(text_content)    \n",
    "        enriched_price = enrich_price_data(cleaned_text)\n",
    "        vector = ollama_embedding.embed_query(enriched_price)\n",
    "\n",
    "        payload = {\n",
    "            \"full_text\": text_content,\n",
    "            \"h1\": str(el.metadata.to_dict().get(\"filename\", \"Unknown File\")),\n",
    "            \"type\": el.category,\n",
    "            \"page\": el.metadata.page_number\n",
    "        }\n",
    "\n",
    "        points.append(PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=vector,\n",
    "            payload=payload\n",
    "        ))\n",
    "\n",
    "    if points:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        print(f\"   âœ… Uploaded {len(points)} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenith-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
